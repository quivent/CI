// Topology Command Handler - CI Topology Management Integration
// Command handlers for all topology operations

use anyhow::{Result, Context};
use colored::Colorize;
use std::collections::HashMap;

use crate::config::Config;
use crate::helpers::command::CommandHelpers;
use crate::topology::{Topologist, TopologyAnalysis, FileCategory};
use crate::errors::CIError;

#[derive(clap::Subcommand)]
pub enum TopologyCommands {
    /// Analyze repository state without creating files
    Analyze {
        #[arg(long, help = "Check if repository has unorganized files")]
        has_unorganized: bool,
    },
    /// Generate detailed commit plan
    Plan {
        #[arg(long, help = "Save plan to local metadata")]
        save: bool,
        #[arg(long, help = "Check if current plan is executable")]
        check: bool,
    },
    /// Execute commit phases
    Execute {
        #[arg(help = "Phase number to execute, or 'all' for complete execution")]
        phase: String,
    },
    /// Show current topology session status
    Status,
    /// Display size change tracking
    Track,
    /// Initialize topological management
    Init,
    /// Remove all topology metadata
    Clean,
    /// Export commit history summary
    Export,
    /// Git repository topology analysis (detailed)
    GitAnalysis,
}

pub async fn topology(command: &TopologyCommands, _config: &Config) -> Result<()> {
    let mut topologist = Topologist::new();

    match command {
        TopologyCommands::Analyze { has_unorganized } => {
            handle_analyze(&topologist, *has_unorganized).await
        },
        TopologyCommands::Plan { save, check } => {
            handle_plan(&mut topologist, *save, *check).await
        },
        TopologyCommands::Execute { phase } => {
            handle_execute(&mut topologist, phase).await
        },
        TopologyCommands::Status => {
            handle_status(&topologist).await
        },
        TopologyCommands::Track => {
            handle_track(&topologist).await
        },
        TopologyCommands::Init => {
            handle_init(&mut topologist).await
        },
        TopologyCommands::Clean => {
            handle_clean(&mut topologist).await
        },
        TopologyCommands::Export => {
            handle_export(&topologist).await
        },
        TopologyCommands::GitAnalysis => {
            handle_git_analysis().await
        },
    }
}

async fn handle_analyze(topologist: &Topologist, has_unorganized: bool) -> Result<()> {
    CommandHelpers::print_command_header(
        "Repository topology analysis",
        "ğŸ”",
        "Topology Management",
        "cyan"
    );

    let analysis = topologist.analyze_repository()
        .map_err(|e| CIError::TopologyError(e.to_string()))?;
    
    if has_unorganized {
        // Silent check for CI/CD integration
        if analysis.repository_stats.total_files > 0 {
            std::process::exit(1); // Has unorganized files
        } else {
            std::process::exit(0); // Repository is organized
        }
    }

    print_analysis_summary(&analysis);
    Ok(())
}

async fn handle_plan(topologist: &mut Topologist, save: bool, check: bool) -> Result<()> {
    CommandHelpers::print_command_header(
        "Generate systematic commit plan",
        "ğŸ“‹",
        "Topology Management", 
        "cyan"
    );

    let analysis = topologist.analyze_repository()
        .map_err(|e| CIError::TopologyError(e.to_string()))?;
    
    if check {
        // Check if plan is executable
        if analysis.commit_phases.is_empty() {
            println!("âœ… Repository is organized, no plan needed");
            return Ok(());
        } else {
            println!("ğŸ“‹ Plan available: {} phases ready for execution", analysis.commit_phases.len());
            return Ok(());
        }
    }

    if analysis.commit_phases.is_empty() {
        println!("âœ… Repository is already organized!");
        return Ok(());
    }

    print_detailed_plan(&analysis);

    if save {
        topologist.initialize()
            .map_err(|e| CIError::TopologyError(e.to_string()))?;
        println!("\nğŸ’¾ Plan saved to .ci-topology/ metadata");
        println!("   Run 'ci topologist execute all' to proceed");
    } else {
        println!("\nğŸ’¡ Run with --save to create executable plan");
    }

    Ok(())
}

async fn handle_execute(topologist: &mut Topologist, phase: &str) -> Result<()> {
    CommandHelpers::print_command_header(
        "Execute topology organization phases",
        "ğŸš€",
        "Topology Management",
        "cyan"
    );

    let analysis = topologist.analyze_repository()
        .map_err(|e| CIError::TopologyError(e.to_string()))?;
    
    if analysis.commit_phases.is_empty() {
        println!("âœ… No phases to execute - repository is organized");
        return Ok(());
    }

    if phase == "all" {
        println!("ğŸš€ Executing all {} phases...\n", analysis.commit_phases.len());
        
        for (i, commit_phase) in analysis.commit_phases.iter().enumerate() {
            let phase_num = i + 1;
            println!("ğŸ“¦ Phase {}: {}", phase_num, commit_phase.commit_message);
            
            let commit_hash = topologist.execute_phase(phase_num, &analysis.commit_phases)
                .map_err(|e| CIError::TopologyError(e.to_string()))?;
            
            println!("   âœ… Commit: {} (+{} estimated lines)", 
                     &commit_hash[..8], commit_phase.estimated_size);
            println!("   ğŸ“ Files: {}", commit_phase.files.len());
            println!();
        }
        
        println!("ğŸ‰ All phases complete! Repository synchronized.");
        
    } else {
        let phase_num: usize = phase.parse()
            .context("Invalid phase number")?;
            
        if phase_num == 0 || phase_num > analysis.commit_phases.len() {
            return Err(anyhow::anyhow!("Phase {} not found. Available: 1-{}", 
                         phase_num, analysis.commit_phases.len()));
        }
        
        let commit_phase = &analysis.commit_phases[phase_num - 1];
        println!("ğŸ“¦ Executing Phase {}: {}", phase_num, commit_phase.commit_message);
        
        let commit_hash = topologist.execute_phase(phase_num, &analysis.commit_phases)
            .map_err(|e| CIError::TopologyError(e.to_string()))?;
        
        println!("âœ… Phase {} Complete: {} (+{} estimated lines)", 
                 phase_num, &commit_hash[..8], commit_phase.estimated_size);
    }

    Ok(())
}

async fn handle_status(topologist: &Topologist) -> Result<()> {
    CommandHelpers::print_command_header(
        "Topology session status",
        "ğŸ“Š",
        "Topology Management",
        "cyan"
    );

    match topologist.get_status()
        .map_err(|e| CIError::TopologyError(e.to_string()))? {
        Some(session) => {
            println!("ğŸ“Š Topology Session Active");
            println!("   Created: {}", session.started);
            println!("   Phases completed: {}/{}", 
                     session.phases.len(), 
                     session.total_planned_phases.unwrap_or(0));
            
            if let Some(last_phase) = session.phases.last() {
                println!("   Last commit: {}", last_phase.commit_hash);
            }
        },
        None => {
            println!("ğŸ“Š No active topology session");
            println!("   Run 'ci topologist plan --save' to start");
        }
    }
    Ok(())
}

async fn handle_track(topologist: &Topologist) -> Result<()> {
    CommandHelpers::print_command_header(
        "Repository size change tracking",
        "ğŸ“ˆ",
        "Topology Management",
        "cyan"
    );

    match topologist.get_status()
        .map_err(|e| CIError::TopologyError(e.to_string()))? {
        Some(session) => {
            println!("ğŸ“ˆ Size Change Tracking");
            println!("   Session: {}", session.session_id);
            
            let mut total_insertions = 0;
            let mut total_files = 0;
            
            for (i, phase) in session.phases.iter().enumerate() {
                println!("   Phase {}: +{} lines, {} files", 
                         i + 1, phase.size_change, phase.files_count);
                total_insertions += phase.size_change;
                total_files += phase.files_count;
            }
            
            println!("   Total Impact: +{} lines, {} files", total_insertions, total_files);
        },
        None => {
            println!("ğŸ“ˆ No tracking data available");
            println!("   Start a session with 'ci topologist plan --save'");
        }
    }
    Ok(())
}

async fn handle_init(topologist: &mut Topologist) -> Result<()> {
    CommandHelpers::print_command_header(
        "Initialize topology management",
        "ğŸ¯",
        "Topology Management",
        "cyan"
    );

    topologist.initialize()
        .map_err(|e| CIError::TopologyError(e.to_string()))?;
    println!("ğŸ¯ Topology management initialized");
    println!("   Metadata directory: .ci-topology/");
    println!("   Next: 'ci topologist analyze' to get started");
    Ok(())
}

async fn handle_clean(topologist: &mut Topologist) -> Result<()> {
    CommandHelpers::print_command_header(
        "Clean topology metadata",
        "ğŸ§¹",
        "Topology Management",
        "cyan"
    );

    topologist.clean()
        .map_err(|e| CIError::TopologyError(e.to_string()))?;
    println!("ğŸ§¹ All topology metadata removed");
    println!("   Repository is clean of all traces");
    Ok(())
}

async fn handle_export(topologist: &Topologist) -> Result<()> {
    CommandHelpers::print_command_header(
        "Export topology session data",
        "ğŸ“¤",
        "Topology Management",
        "cyan"
    );

    match topologist.get_status()
        .map_err(|e| CIError::TopologyError(e.to_string()))? {
        Some(session) => {
            // Export in JSON format for programmatic use
            let json = serde_json::to_string_pretty(&session)
                .context("Failed to serialize session data")?;
            println!("{}", json);
        },
        None => {
            println!("{{}}");  // Empty JSON object
        }
    }
    Ok(())
}

fn print_analysis_summary(analysis: &TopologyAnalysis) {
    println!("ğŸ” Repository Analysis Complete");
    println!("â”œâ”€â”€ {} total files detected", analysis.repository_stats.total_files);
    println!("â”œâ”€â”€ {} untracked files", analysis.repository_stats.untracked_files);  
    println!("â”œâ”€â”€ {} modified files", analysis.repository_stats.modified_files);
    println!("â”œâ”€â”€ Estimated growth: +{} lines", analysis.repository_stats.estimated_total_size);
    println!("â””â”€â”€ Suggested: {}-phase commit strategy", analysis.repository_stats.suggested_phases);
    
    if !analysis.commit_phases.is_empty() {
        println!("\nğŸ“‚ File Categories:");
        let mut category_summary: HashMap<String, usize> = HashMap::new();
        
        for file in &analysis.category_analysis.files {
            let category_name = format!("{:?}", file.category);
            *category_summary.entry(category_name).or_insert(0) += 1;
        }
        
        for (category, count) in category_summary {
            let icon = match category.as_str() {
                "Configuration" => "âš™ï¸",
                "Documentation" => "ğŸ“š",
                "SourceCode" => "ğŸ’»",
                "DevelopmentTools" => "ğŸ”§",
                "MediaAssets" => "ğŸ¨",
                _ => "ğŸ“„",
            };
            println!("   {} {}: {} files", icon, category, count);
        }
        
        println!("\nğŸ’¡ Run 'ci topologist plan --save' to proceed");
    }
}

fn print_detailed_plan(analysis: &TopologyAnalysis) {
    println!("ğŸ“‹ Detailed Commit Plan ({} phases)", analysis.commit_phases.len());
    println!();
    
    for (i, phase) in analysis.commit_phases.iter().enumerate() {
        let phase_num = i + 1;
        let category_icon = match phase.category {
            FileCategory::Configuration => "âš™ï¸",
            FileCategory::Documentation => "ğŸ“š", 
            FileCategory::SourceCode => "ğŸ’»",
            FileCategory::DevelopmentTools => "ğŸ”§",
            FileCategory::MediaAssets => "ğŸ¨",
            _ => "ğŸ“„",
        };
        
        println!("Phase {}: {} {}", phase_num, category_icon, phase.commit_message);
        println!("â”œâ”€â”€ Files: {} (+{} estimated lines)", phase.files.len(), phase.estimated_size);
        println!("â”œâ”€â”€ Category: {:?}", phase.category);
        
        // Show first few files as examples
        let max_show = 3;
        for (j, file) in phase.files.iter().take(max_show).enumerate() {
            let prefix = if j == phase.files.len().min(max_show) - 1 { "â””â”€â”€" } else { "â”œâ”€â”€" };
            println!("{}   {}", prefix, file.path);
        }
        
        if phase.files.len() > max_show {
            println!("â””â”€â”€   ... and {} more files", phase.files.len() - max_show);
        }
        println!();
    }
    
    let total_size: usize = analysis.commit_phases.iter().map(|p| p.estimated_size).sum();
    println!("ğŸ“Š Total Impact: +{} estimated lines across {} commits", total_size, analysis.commit_phases.len());
}

async fn handle_git_analysis() -> Result<()> {
    CommandHelpers::print_command_header(
        "Git repository topology analysis",
        "ğŸ”",
        "Topology Management",
        "cyan"
    );

    println!("# Git Repository Topography Analysis\n");
    
    // Get total .git size
    let git_size = get_git_directory_size()?;
    println!("**Total .git size: {:.1}MB**\n", git_size);
    
    // Analyze directory structure
    analyze_git_directory_structure()?;
    
    // Get object statistics
    analyze_object_distribution()?;
    
    // Analyze content by file type
    analyze_content_by_file_type()?;
    
    // Get largest files
    show_largest_files()?;

    Ok(())
}

fn get_git_directory_size() -> Result<f64> {
    use std::process::Command;
    
    let output = Command::new("du")
        .args(&["-sm", ".git"])
        .output()
        .context("Failed to execute du command")?;
    
    let output_str = std::str::from_utf8(&output.stdout)
        .context("Invalid UTF-8 in du output")?;
    let size_str = output_str.split_whitespace().next().unwrap_or("0");
    size_str.parse::<f64>()
        .context("Failed to parse git directory size")
}

fn analyze_git_directory_structure() -> Result<()> {
    use std::process::Command;
    
    println!("## Directory Structure");
    
    let output = Command::new("sh")
        .arg("-c")
        .arg("du -sh .git/* 2>/dev/null | sort -hr")
        .output()
        .context("Failed to analyze git directory")?;
    
    let output_str = std::str::from_utf8(&output.stdout)
        .context("Invalid UTF-8 in directory analysis")?;
    let total_size = get_git_directory_size()? * 1024.0; // Convert to KB
    
    println!("```");
    println!(".git/");
    
    for line in output_str.lines() {
        let parts: Vec<&str> = line.split_whitespace().collect();
        if parts.len() >= 2 {
            let size_str = parts[0];
            let path = parts[1].replace(".git/", "");
            
            // Convert size to KB
            let size_kb = parse_size_to_kb(size_str);
            let percentage = (size_kb / total_size) * 100.0;
            
            let description = match path.as_str() {
                "objects" => "- Compressed object storage",
                "index" => "- Staging area state", 
                "hooks" => "- Git hooks",
                "filter-repo" => "- Recent filter operations",
                "info" => "- Repository metadata",
                _ => "- Config, refs, logs"
            };
            
            println!("â”œâ”€â”€ {:15} {:>6} ({:4.1}%) {}", 
                path, size_str, percentage, description);
        }
    }
    println!("```\n");
    
    // Analyze pack files specifically
    analyze_pack_files()?;
    Ok(())
}

fn analyze_pack_files() -> Result<()> {
    use std::process::Command;
    
    let output = Command::new("ls")
        .args(&["-lh", ".git/objects/pack/"])
        .output();
    
    if let Ok(output) = output {
        let output_str = std::str::from_utf8(&output.stdout)
            .context("Invalid UTF-8 in pack files listing")?;
        if !output_str.is_empty() {
            println!("### Pack File Details:");
            println!("```");
            for line in output_str.lines().skip(1) { // Skip "total" line
                if line.contains(".pack") {
                    let parts: Vec<&str> = line.split_whitespace().collect();
                    if parts.len() >= 5 {
                        println!("Pack file:     {} - All git objects compressed", parts[4]);
                    }
                } else if line.contains(".idx") {
                    let parts: Vec<&str> = line.split_whitespace().collect();
                    if parts.len() >= 5 {
                        println!("Index file:    {} - Pack file index", parts[4]);
                    }
                }
            }
            println!("```\n");
        }
    }
    Ok(())
}

fn analyze_object_distribution() -> Result<()> {
    use std::process::Command;
    
    println!("## Object Distribution");
    
    // Get object count statistics
    let output = Command::new("git")
        .args(&["count-objects", "-v"])
        .output()
        .context("Failed to get object statistics")?;
    
    let output_str = std::str::from_utf8(&output.stdout)
        .context("Invalid UTF-8 in git count-objects output")?;
    let mut in_pack = 0;
    let mut size_pack = 0;
    
    for line in output_str.lines() {
        if line.starts_with("in-pack ") {
            in_pack = line.split_whitespace().nth(1).unwrap_or("0").parse().unwrap_or(0);
        }
        if line.starts_with("size-pack ") {
            size_pack = line.split_whitespace().nth(1).unwrap_or("0").parse().unwrap_or(0);
        }
    }
    
    // Analyze object types
    let output = Command::new("sh")
        .arg("-c")
        .arg("git rev-list --objects --all | git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' | awk '{type[$1]++; size[$1]+=$3} END {for(t in type) printf \"%s %d %d\\n\", t, type[t], size[t]}' | sort -k3 -nr")
        .output()
        .context("Failed to analyze object types")?;
    
    let output_str = std::str::from_utf8(&output.stdout)
        .context("Invalid UTF-8 in object analysis")?;
    let mut total_uncompressed = 0;
    
    println!("```");
    println!("Object Type    Count    Uncompressed    Compressed*");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    
    for line in output_str.lines() {
        let parts: Vec<&str> = line.split_whitespace().collect();
        if parts.len() >= 3 {
            let obj_type = parts[0];
            let count: i32 = parts[1].parse().unwrap_or(0);
            let size: i32 = parts[2].parse().unwrap_or(0);
            total_uncompressed += size;
            
            let compressed_estimate = (size as f64 * size_pack as f64 / (total_uncompressed as f64 + 1.0)) as i32;
            
            println!("{:10}: {:6} objects    {:6.0} KB       ~{:4} KB", 
                format!("{}s", obj_type), count, size as f64 / 1024.0, compressed_estimate / 1024);
        }
    }
    
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Total:         {:6} objects    {:6.0} KB       {:4} KB", 
        in_pack, total_uncompressed as f64 / 1024.0, size_pack);
    println!("```\n");
    Ok(())
}

fn analyze_content_by_file_type() -> Result<()> {
    use std::process::Command;
    
    println!("## Content Breakdown by File Type");
    
    let output = Command::new("sh")
        .arg("-c")
        .arg(r#"git rev-list --objects --all | git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' | sed -n 's/^blob //p' | awk '{
            file=$3
            size=$2
            if (file ~ /\.rs$/) { rust_size += size; rust_count++ }
            else if (file ~ /\.md$/) { md_size += size; md_count++ }
            else if (file ~ /\.js$/) { js_size += size; js_count++ }
            else if (file ~ /\.html$/) { html_size += size; html_count++ }
            else if (file ~ /\.json$/) { json_size += size; json_count++ }
            else if (file ~ /\.(sh|bash)$/) { script_size += size; script_count++ }
            else { other_size += size; other_count++ }
        } END {
            total_size = rust_size + md_size + js_size + html_size + json_size + script_size + other_size
            printf "Markdown %d %.1f %.1f\n", md_count, md_size/1024, (md_size/total_size)*100
            printf "Rust(.rs) %d %.1f %.1f\n", rust_count, rust_size/1024, (rust_size/total_size)*100
            printf "Scripts %d %.1f %.1f\n", script_count, script_size/1024, (script_size/total_size)*100
            printf "Other %d %.1f %.1f\n", other_count, other_size/1024, (other_size/total_size)*100
            printf "JavaScript %d %.1f %.1f\n", js_count, js_size/1024, (js_size/total_size)*100
            printf "JSON %d %.1f %.1f\n", json_count, json_size/1024, (json_size/total_size)*100
            printf "HTML %d %.1f %.1f\n", html_count, html_size/1024, (html_size/total_size)*100
        }'"#)
        .output()
        .context("Failed to analyze content by file type")?;
    
    let output_str = std::str::from_utf8(&output.stdout)
        .context("Invalid UTF-8 in content analysis")?;
    
    println!("```");
    println!("File Type       Files    Size (KB)    % of Content");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    
    for line in output_str.lines() {
        let parts: Vec<&str> = line.split_whitespace().collect();
        if parts.len() >= 4 {
            let file_type = parts[0];
            let count: i32 = parts[1].parse().unwrap_or(0);
            let size: f64 = parts[2].parse().unwrap_or(0.0);
            let percentage: f64 = parts[3].parse().unwrap_or(0.0);
            
            println!("{:15}: {:6}    {:8.1}     {:4.1}%", 
                file_type, count, size, percentage);
        }
    }
    println!("```\n");
    Ok(())
}

fn show_largest_files() -> Result<()> {
    use std::process::Command;
    
    println!("## Largest Files");
    
    let output = Command::new("sh")
        .arg("-c")
        .arg("git rev-list --objects --all | git cat-file --batch-check='%(objecttype) %(objectname) %(objectsize) %(rest)' | sed -n 's/^blob //p' | sort -k2 -nr | head -10")
        .output()
        .context("Failed to get largest files")?;
    
    let output_str = std::str::from_utf8(&output.stdout)
        .context("Invalid UTF-8 in largest files analysis")?;
    
    println!("```");
    println!("Size (KB)  File");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    
    for line in output_str.lines() {
        let parts: Vec<&str> = line.split_whitespace().collect();
        if parts.len() >= 3 {
            let size: f64 = parts[1].parse().unwrap_or(0.0) / 1024.0;
            let file = parts[2];
            
            println!("{:8.1}   {}", size, file);
        }
    }
    println!("```\n");
    
    // Calculate compression ratio
    let total_size = get_git_directory_size()?;
    let compression_ratio = ((total_size * 1024.0 - 2640.0) / (total_size * 1024.0)) * 100.0;
    
    println!("**Key Insights:**");
    println!("- **Efficient compression**: ~{:.0}% compression ratio", compression_ratio);
    println!("- **Healthy distribution**: No single massive files after optimization");
    println!("- **Total objects**: Efficiently packed in compressed storage");
    println!("\n*Compressed sizes are estimates based on pack compression ratio");
    Ok(())
}

fn parse_size_to_kb(size_str: &str) -> f64 {
    let size_str = size_str.trim();
    
    if size_str.ends_with("M") {
        let num: f64 = size_str.trim_end_matches("M").parse().unwrap_or(0.0);
        num * 1024.0
    } else if size_str.ends_with("K") {
        let num: f64 = size_str.trim_end_matches("K").parse().unwrap_or(0.0);
        num
    } else if size_str.ends_with("B") {
        let num: f64 = size_str.trim_end_matches("B").parse().unwrap_or(0.0);
        num / 1024.0
    } else {
        // Assume bytes if no suffix
        let num: f64 = size_str.parse().unwrap_or(0.0);
        num / 1024.0
    }
}